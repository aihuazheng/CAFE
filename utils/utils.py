import numpy as np
from torch import nn
import torch
import os

# med_frq = [0.382900, 0.452448, 0.637584, 0.377464, 0.585595,
#            0.479574, 0.781544, 0.982534, 1.017466, 0.624581,
#            2.589096, 0.980794, 0.920340, 0.667984, 1.172291,
#            0.862240, 0.921714, 2.154782, 1.187832, 1.178115,
#            1.848545, 1.428922, 2.849658, 0.771605, 1.656668,
#            4.483506, 2.209922, 1.120280, 2.790182, 0.706519,
#            3.994768, 2.220004, 0.972934, 1.481525, 5.342475,
#            0.750738, 4.040773]
#
model_urls = {
    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',
    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',
    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',
    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',
    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',
}
#
# label_colours = [(0, 0, 0),
#                  # 0=background
#                  (148, 65, 137), (255, 116, 69), (86, 156, 137),
#                  (202, 179, 158), (155, 99, 235), (161, 107, 108),
#                  (133, 160, 103), (76, 152, 126), (84, 62, 35),
#                  (44, 80, 130), (31, 184, 157), (101, 144, 77),
#                  (23, 197, 62), (141, 168, 145), (142, 151, 136),
#                  (115, 201, 77), (100, 216, 255), (57, 156, 36),
#                  (88, 108, 129), (105, 129, 112), (42, 137, 126),
#                  (155, 108, 249), (166, 148, 143), (81, 91, 87),
#                  (100, 124, 51), (73, 131, 121), (157, 210, 220),
#                  (134, 181, 60), (221, 223, 147), (123, 108, 131),
#                  (161, 66, 179), (163, 221, 160), (31, 146, 98),
#                  (99, 121, 30), (49, 89, 240), (116, 108, 9),
#                  (161, 176, 169), (80, 29, 135), (177, 105, 197),
#                  (139, 110, 246)]


class CrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None):
        super(CrossEntropyLoss2d, self).__init__()
        self.ce_loss = nn.CrossEntropyLoss(size_average=False, reduce=False)

    def forward(self, inputs_scales, targets_scales):
        losses = []
        for inputs, targets in zip(inputs_scales, targets_scales):
            mask = targets >=0
            targets_m = targets.clone()
            # targets_m[mask] -= 1
            loss_all = self.ce_loss(inputs, targets_m.long())
            losses.append(torch.sum(torch.masked_select(loss_all, mask)) / torch.sum(mask.float()))
        total_loss = sum(losses)
        return total_loss

#
# def color_label(label):
#     label = label.clone().cpu().data.numpy()
#     colored_label = np.vectorize(lambda x: label_colours[int(x)])
#
#     colored = np.asarray(colored_label(label)).astype(np.float32)
#     colored = colored.squeeze()
#
#     try:
#         return torch.from_numpy(colored.transpose([1, 0, 2, 3]))
#     except ValueError:
#         return torch.from_numpy(colored[np.newaxis, ...])


def print_log(global_step, epoch, local_count, count_inter, dataset_size, loss, time_inter):
    print('Step: {:>5} Train Epoch: {:>3} [{:>4}/{:>4} ({:3.1f}%)]    '
          'Loss: {:.6f} [{:.2f}s every {:>4} data]'.format(
        global_step, epoch, local_count, dataset_size,
        100. * local_count / dataset_size, loss.data, time_inter, count_inter))


def save_ckpt(ckpt_dir, model, optimizer, global_step, epoch, local_count, num_train):
    # usually this happens only on the start of a epoch
    epoch_float = epoch + (local_count / num_train)
    state = {
        'global_step': global_step,
        'epoch': epoch_float,
        'state_dict': model.state_dict(),
        'optimizer': optimizer.state_dict(),
    }
    ckpt_model_filename = "ckpt_epoch_{:0.2f}.pth".format(epoch_float)
    path = os.path.join(ckpt_dir, ckpt_model_filename)
    torch.save(state, path)
    print('{:>2} has been successfully saved'.format(path))


def load_ckpt(model, optimizer, model_file, device):
    if os.path.isfile(model_file):
        print("=> loading checkpoint '{}'".format(model_file))
        if device.type == 'cuda':
            checkpoint = torch.load(model_file)
        else:
            checkpoint = torch.load(model_file, map_location=lambda storage, loc: storage)
        model.load_state_dict(checkpoint['state_dict'])
        if optimizer:
            optimizer.load_state_dict(checkpoint['optimizer'])
        print("=> loaded checkpoint '{}' (epoch {})"
              .format(model_file, checkpoint['epoch']))
        step = checkpoint['global_step']
        epoch = checkpoint['epoch']
        return step, epoch
    else:
        print("=> no checkpoint found at '{}'".format(model_file))
        os._exit(0)
